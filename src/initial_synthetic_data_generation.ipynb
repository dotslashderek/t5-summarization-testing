{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initial Synthetic Data Generation\n\nRecreate the primary synthetic dataset by streaming Dolly-15k prompts through `gpt-5-nano` with the original lightweight compression instruction. The helper functions in `workflows/generation.py` manage token counting, progress persistence, and resumable batching."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage\n\n1. Ensure your OpenAI API key is available in `OPENAI_API_KEY`.\n2. Optionally adjust `limit` for smoke tests.\n3. Run the generation cell to (re)populate `src/training_data/dolly-prompt-compression.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from workflows.generation import ensure_base_prompts, primary_config, run_generation, summarize_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "limit = None\nconfig = primary_config(limit=limit)\nensure_base_prompts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_generation(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summarize_dataset(config.output_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}